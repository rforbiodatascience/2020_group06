---
title: "slides_Sebastian"
author: "Sebastian Sbirna, Sule Altinas & Stanley Frederiksen"
date: "5/13/2020"
output: 
  ioslides_presentation:
    widescreen: true
    smaller: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Introduction
### The dataset
<br>
Our project has used a modified version of this data, which is available from Kaggle: <https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset>, by _Sudalai Rajkumar_, which consists of:

* patient data from the first 2 months of the outbreak 
* time-series data about the spread of the virus

Please note that infection spreading information and data regarding COVID19 is being updated every day. The data used for this project was first pulled on 15 April 2020, and has been updated accordingly since then. 

*__The last update of the data was done on 13 May 2020.__*


## Methodology
### Data Import & Wrangling

* This modified version of the JHU dataset initially contained 9 "untidy" dataframes:
  * `covid_19_data.csv`: daily information on confirmed, recovered and deceased patients
  * `COVID19_line_list_data.csv`: first patient data file, with ~1000 records
  * `COVID19_open_line_list.csv`: second patient data file, with ~10000 records
  * `time_series_covid_19_confirmed.csv`: daily number of confirmed cases around the world 
  * `time_series_covid_19_confirmed_US.csv`: daily number of confirmed cases only for US and its states
  * `time_series_covid_19_deaths.csv`: daily number of deceased cases around the world
  * `time_series_covid_19_deaths_US.csv`: daily number of deceased cases only for US and its states
  * `time_series_covid_19_recovered.csv`: daily number of recovered cases around the world
  * `wpp2019_total_population.csv`: data downloaded from <https://population.un.org/wpp/Download/Standard/CSV/> which has the total population of a country in 2019
  
  
## Methodology
### Data Import & Wrangling

* All these dataframes were very dirty
  * Different number and type of attributes
  * Different formats for storing country & provinces
  * Different methodology of collecting time-series data
  * Empty and extremely sparse columns
  * Conceptual string duplicates (e.g. _runny nose_ and _nasal discharge_ )
  * ... and more
  
  
## Methodology
### Data Import & Wrangling

Heavy data wrangling & tidying procedures were necessary, in order to achieve consistency across the different datasets:

* ___Column renaming to a common scheme___
* ___Remove data inconsistencies in province and country strings___
* ___Transformation of missing values to a common format___
* ___Empty and unnecessary column removal___
* ___Replace conceptual duplicates in the patient symptom data___
* ___Fixing erroneous age values___
* ___Date conversion into a unitary format___
* ___Tidying time-series dataset into long format (date column)___
* ___Tidying patient data into wide format (symptoms column)___
  
## Methodology
### Data Import & Wrangling
<br>

### _How did we achieve data wrangling?_
* Very heavy use of `stringr` and __`regexp (regular expressions)`__
* `dplyr` to the rescue - filtering, mutating, grouping, summarizing
* `lubridate` for dates conversion
* Achieved a consistent andn easy-to-understand workflow through _piping_ (`%>%`)